# pos_test_offset<-t(t(x_vec_test)-pos_mean)
# pos_test_scaled<-t(t(pos_test_offset)/pos_sd)
# pos_test_log_prob<--(1/2)*rowSums(apply(pos_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(pos_sd))
#
# # Solve for log probability that each feature vector corresponds to a negative label
# neg_test_offset<-t(t(x_vec_test)-neg_mean)
# neg_test_scaled<-t(t(neg_test_offset)/neg_sd)
# neg_test_log_prob<--(1/2)*rowSums(apply(neg_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(neg_sd))
#
# # record percentage guessed correctly in scores array
# guesses_test<-pos_test_log_prob>neg_test_log_prob
# num_correct_test<-guesses_test==y_vec_test
# test_score[iter]<-sum(num_correct_test)/(sum(num_correct_test)+sum(!num_correct_test))
}
# print(test_score)
# Build a simple naive Bayes classifier to classify this data set.
# load library
library(klaR)
library(caret)
# set current work path
setwd('.')
# read in csv file
input_data<-read.csv('pima-indians-diabetes.csv', header=FALSE)
# split the inputdata
input_x <- input_data[,-c(9)]  # features
input_y <- input_data[,9]      # labels
# number of times
iters = 10
# initialize accuracy
train_accuracy <- array(dim=iters)
test_accuracy <- array(dim=iters)
# run 10 times
for (iter in 1:iters)
{
# TRAIN
# extract train data by randomly assigning 80% of the data to train
train_index <- createDataPartition(y = input_y, p=.8, list=FALSE)
# extract *training* feature vectors and labels
train_x <- input_x[train_index, ]
train_y <- input_y[train_index]
# get positive index
positive_index <- train_y == 1
# get positive & negative feature data
train_x_positive <- train_x[positive_index, ]
train_x_negative <- train_x[!positive_index,]
# use a normal distribution to model each of the class-conditional distributions
# calculate mean
train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
# calculate standard deviation
train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
# calculate log probability
train_x_positive_offset <- t(t(train_x_positive) - train_x_positive_mean)
train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
train_x_positive_log_prob <- -(1/2)*rowSums(train_x_positive_scaled * train_x_positive_scaled) - sum(log(train_x_positive_sd))
train_x_negative_offset <- t(t(train_x_negative) - train_x_negative_mean)
train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
train_x_negative_log_prob <- -(1/2)*rowSums(train_x_negative_scaled * train_x_negative_scaled) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
guesses_train <- train_x_positive_log_prob > train_x_negative_log_prob
num_correct_train <- guesses_train == train_y
train_accuracy[iter]<-sum(num_correct_train)/(sum(num_correct_train)+sum(!num_correct_train))
print(train_accuracy[iter])
# ## evaluating - testing data
#
# # extract *testing* feature vectors and labels
# x_vec_test<-x_vec[-wtd, ]
# y_vec_test<-y_vec[-wtd]
#
# # Solve for log probability that each feature vector corresponds to a positive label
# pos_test_offset<-t(t(x_vec_test)-pos_mean)
# pos_test_scaled<-t(t(pos_test_offset)/pos_sd)
# pos_test_log_prob<--(1/2)*rowSums(apply(pos_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(pos_sd))
#
# # Solve for log probability that each feature vector corresponds to a negative label
# neg_test_offset<-t(t(x_vec_test)-neg_mean)
# neg_test_scaled<-t(t(neg_test_offset)/neg_sd)
# neg_test_log_prob<--(1/2)*rowSums(apply(neg_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(neg_sd))
#
# # record percentage guessed correctly in scores array
# guesses_test<-pos_test_log_prob>neg_test_log_prob
# num_correct_test<-guesses_test==y_vec_test
# test_score[iter]<-sum(num_correct_test)/(sum(num_correct_test)+sum(!num_correct_test))
}
# print(test_score)
# Build a simple naive Bayes classifier to classify this data set.
# load library
library(klaR)
library(caret)
# set current work path
setwd('.')
# read in csv file
input_data<-read.csv('pima-indians-diabetes.csv', header=FALSE)
# split the inputdata
input_x <- input_data[,-c(9)]  # features
input_y <- input_data[,9]      # labels
# number of times
iters = 10
# initialize accuracy
train_accuracy <- array(dim=iters)
test_accuracy <- array(dim=iters)
# run 10 times
for (iter in 1:iters)
{
# TRAIN
# extract train data by randomly assigning 80% of the data to train
train_index <- createDataPartition(y = input_y, p=.8, list=FALSE)
# extract *training* feature vectors and labels
train_x <- input_x[train_index, ]
train_y <- input_y[train_index]
# get positive index
positive_index <- train_y == 1
# get positive & negative feature data
train_x_positive <- train_x[positive_index, ]
train_x_negative <- train_x[!positive_index,]
# use a normal distribution to model each of the class-conditional distributions
# calculate mean
train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
# calculate standard deviation
train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
# calculate log probability
train_x_positive_offset <- t(t(train_x_positive) - train_x_positive_mean)
train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
train_x_positive_log_prob <- -(1/2)*rowSums(apply(train_x_positive_scaled, c(1, 2), function(x)x^2), na.rm=TRUE) - sum(log(train_x_positive_sd))
train_x_negative_offset <- t(t(train_x_negative) - train_x_negative_mean)
train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
train_x_negative_log_prob <- -(1/2)*rowSums(apply(train_x_negative_scaled, c(1, 2), function(x)x^2), na.rm=TRUE) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
guesses_train <- train_x_positive_log_prob > train_x_negative_log_prob
num_correct_train <- guesses_train == train_y
train_accuracy[iter]<-sum(num_correct_train)/(sum(num_correct_train)+sum(!num_correct_train))
print(train_accuracy[iter])
# ## evaluating - testing data
#
# # extract *testing* feature vectors and labels
# x_vec_test<-x_vec[-wtd, ]
# y_vec_test<-y_vec[-wtd]
#
# # Solve for log probability that each feature vector corresponds to a positive label
# pos_test_offset<-t(t(x_vec_test)-pos_mean)
# pos_test_scaled<-t(t(pos_test_offset)/pos_sd)
# pos_test_log_prob<--(1/2)*rowSums(apply(pos_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(pos_sd))
#
# # Solve for log probability that each feature vector corresponds to a negative label
# neg_test_offset<-t(t(x_vec_test)-neg_mean)
# neg_test_scaled<-t(t(neg_test_offset)/neg_sd)
# neg_test_log_prob<--(1/2)*rowSums(apply(neg_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(neg_sd))
#
# # record percentage guessed correctly in scores array
# guesses_test<-pos_test_log_prob>neg_test_log_prob
# num_correct_test<-guesses_test==y_vec_test
# test_score[iter]<-sum(num_correct_test)/(sum(num_correct_test)+sum(!num_correct_test))
}
# print(test_score)
# Build a simple naive Bayes classifier to classify this data set.
# load library
library(klaR)
library(caret)
# set current work path
setwd('.')
# read in csv file
input_data<-read.csv('pima-indians-diabetes.csv', header=FALSE)
# split the inputdata
input_x <- input_data[,-c(9)]  # features
input_y <- input_data[,9]      # labels
# number of times
iters = 10
# initialize accuracy
train_accuracy <- array(dim=iters)
test_accuracy <- array(dim=iters)
# run 10 times
for (iter in 1:iters)
{
# TRAIN
# extract train data by randomly assigning 80% of the data to train
train_index <- createDataPartition(y = input_y, p=.8, list=FALSE)
# extract *training* feature vectors and labels
train_x <- input_x[train_index, ]
train_y <- input_y[train_index]
# get positive index
positive_index <- train_y > 0
# get positive & negative feature data
train_x_positive <- train_x[positive_index, ]
train_x_negative <- train_x[!positive_index,]
# use a normal distribution to model each of the class-conditional distributions
# calculate mean
train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
# calculate standard deviation
train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
# calculate log probability
train_x_positive_offset <- t(t(train_x_positive) - train_x_positive_mean)
train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
train_x_positive_log_prob <- -(1/2)*rowSums(apply(train_x_positive_scaled, c(1, 2), function(x)x^2), na.rm=TRUE) - sum(log(train_x_positive_sd))
train_x_negative_offset <- t(t(train_x_negative) - train_x_negative_mean)
train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
train_x_negative_log_prob <- -(1/2)*rowSums(apply(train_x_negative_scaled, c(1, 2), function(x)x^2), na.rm=TRUE) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
guesses_train <- train_x_positive_log_prob > train_x_negative_log_prob
num_correct_train <- guesses_train == train_y
train_accuracy[iter]<-sum(num_correct_train)/(sum(num_correct_train)+sum(!num_correct_train))
print(train_accuracy[iter])
# ## evaluating - testing data
#
# # extract *testing* feature vectors and labels
# x_vec_test<-x_vec[-wtd, ]
# y_vec_test<-y_vec[-wtd]
#
# # Solve for log probability that each feature vector corresponds to a positive label
# pos_test_offset<-t(t(x_vec_test)-pos_mean)
# pos_test_scaled<-t(t(pos_test_offset)/pos_sd)
# pos_test_log_prob<--(1/2)*rowSums(apply(pos_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(pos_sd))
#
# # Solve for log probability that each feature vector corresponds to a negative label
# neg_test_offset<-t(t(x_vec_test)-neg_mean)
# neg_test_scaled<-t(t(neg_test_offset)/neg_sd)
# neg_test_log_prob<--(1/2)*rowSums(apply(neg_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(neg_sd))
#
# # record percentage guessed correctly in scores array
# guesses_test<-pos_test_log_prob>neg_test_log_prob
# num_correct_test<-guesses_test==y_vec_test
# test_score[iter]<-sum(num_correct_test)/(sum(num_correct_test)+sum(!num_correct_test))
}
# print(test_score)
warnings()
# # Build a simple naive Bayes classifier to classify this data set.
#
# # load library
# library(klaR)
# library(caret)
#
# # set current work path
# setwd('.')
#
# # read in csv file
# input_data<-read.csv('pima-indians-diabetes.csv', header=FALSE)
#
# # split the inputdata
# input_x <- input_data[,-c(9)]  # features
# input_y <- input_data[,9]      # labels
#
# # number of times
# iters = 10
#
# # initialize accuracy
# train_accuracy <- array(dim=iters)
# test_accuracy <- array(dim=iters)
#
# # run 10 times
# for (iter in 1:iters)
# {
#   # TRAIN
#   # extract train data by randomly assigning 80% of the data to train
#   train_index <- createDataPartition(y = input_y, p=.8, list=FALSE)
#
#   # extract *training* feature vectors and labels
#   train_x <- input_x[train_index, ]
#   train_y <- input_y[train_index]
#
#   # get positive index
#   positive_index <- train_y > 0
#
#   # get positive & negative feature data
#   train_x_positive <- train_x[positive_index, ]
#   train_x_negative <- train_x[!positive_index,]
#
#   # use a normal distribution to model each of the class-conditional distributions
#   # calculate mean
#   train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
#   train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
#
#   # calculate standard deviation
#   train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
#   train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
#
#   # calculate log probability
#   train_x_positive_offset <- t(t(train_x_positive) - train_x_positive_mean)
#   train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
#   train_x_positive_log_prob <- -(1/2)*rowSums(apply(train_x_positive_scaled, c(1, 2), function(x)x^2), na.rm=TRUE) - sum(log(train_x_positive_sd))
#
#   train_x_negative_offset <- t(t(train_x_negative) - train_x_negative_mean)
#   train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
#   train_x_negative_log_prob <- -(1/2)*rowSums(apply(train_x_negative_scaled, c(1, 2), function(x)x^2), na.rm=TRUE) - sum(log(train_x_negative_sd))
#
#   # record percentage guessed correctly in scores array
#   guesses_train <- train_x_positive_log_prob > train_x_negative_log_prob
#   num_correct_train <- guesses_train == train_y
#   train_accuracy[iter]<-sum(num_correct_train)/(sum(num_correct_train)+sum(!num_correct_train))
#
#   print(train_accuracy[iter])
#
#   # ## evaluating - testing data
#   #
#   # # extract *testing* feature vectors and labels
#   # x_vec_test<-x_vec[-wtd, ]
#   # y_vec_test<-y_vec[-wtd]
#   #
#   # # Solve for log probability that each feature vector corresponds to a positive label
#   # pos_test_offset<-t(t(x_vec_test)-pos_mean)
#   # pos_test_scaled<-t(t(pos_test_offset)/pos_sd)
#   # pos_test_log_prob<--(1/2)*rowSums(apply(pos_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(pos_sd))
#   #
#   # # Solve for log probability that each feature vector corresponds to a negative label
#   # neg_test_offset<-t(t(x_vec_test)-neg_mean)
#   # neg_test_scaled<-t(t(neg_test_offset)/neg_sd)
#   # neg_test_log_prob<--(1/2)*rowSums(apply(neg_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(neg_sd))
#   #
#   # # record percentage guessed correctly in scores array
#   # guesses_test<-pos_test_log_prob>neg_test_log_prob
#   # num_correct_test<-guesses_test==y_vec_test
#   # test_score[iter]<-sum(num_correct_test)/(sum(num_correct_test)+sum(!num_correct_test))
# }
#
# # print(test_score)
setwd('.')
wdat<-read.csv('pima-indians-diabetes.txt', header=FALSE)
library(klaR)
library(caret)
# split the input data into feature vectors and associated label
x_vec<-wdat[,-c(9)]
y_vec<-wdat[,9]
# remove 0 entries from feature vectors and replace them with NA (optional operation)
#for (i in c(3, 5, 6, 8)) {
#  zeros<-x_vec[, i]==0
#  x_vec[zeros, i]=NA
#}
# allocate space for training/testing results
train_score<-array(dim=10)
test_score<-array(dim=10)
# run training/testing 10 times
for (iter in 1:10) {
## training
# get indicies to use for training
wtd<-createDataPartition(y=y_vec, p=.8, list=FALSE)
# extract *training* feature vectors and labels
x_vec_train<-x_vec[wtd, ]
y_vec_train<-y_vec[wtd]
# split into postive and negative *training* sets
pos_train_example_flag<-y_vec_train>0
pos_train_examples<-x_vec_train[pos_train_example_flag, ]
neg_train_examples<-x_vec_train[!pos_train_example_flag,]
# extract *testing* feature vectors and labels
x_vec_test<-x_vec[-wtd, ]
y_vec_test<-y_vec[-wtd]
# solve for positive mean and std.dev
pos_mean<-sapply(pos_train_examples, mean, na.rm=TRUE)
pos_sd<-sapply(pos_train_examples, sd, na.rm=TRUE)
# solve for negative mean and std.dev
neg_mean<-sapply(neg_train_examples, mean, na.rm=TRUE)
neg_sd<-sapply(neg_train_examples, sd, na.rm=TRUE)
## evaluating - training data
# Solve for log probability that each feature vector corresponds to a positive label
pos_train_offset<-t(t(x_vec_train)-pos_mean)
pos_train_scaled<-t(t(pos_train_offset)/pos_sd)
pos_train_log_prob<--(1/2)*rowSums(apply(pos_train_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(pos_sd))
# Solve for log probability that each feature vector corresponds to a negative label
neg_train_offset<-t(t(x_vec_train)-neg_mean)
neg_train_scaled<-t(t(neg_train_offset)/neg_sd)
neg_train_log_prob<--(1/2)*rowSums(apply(neg_train_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(neg_sd))
# record percentage guessed correctly in scores array
guesses_train<-pos_train_log_prob>neg_train_log_prob
num_correct_train<-guesses_train==y_vec_train
train_score[iter]<-sum(num_correct_train)/(sum(num_correct_train)+sum(!num_correct_train))
}
print(train_score)
# Build a simple naive Bayes classifier to classify this data set.
# load library
library(klaR)
library(caret)
# set current work path
setwd('.')
# read in csv file
input_data<-read.csv('pima-indians-diabetes.txt', header=FALSE)
# split the inputdata
input_x <- input_data[,-c(9)]  # features
input_y <- input_data[,9]      # labels
# number of times
iters = 10
# initialize accuracy
train_accuracy <- array(dim=iters)
test_accuracy <- array(dim=iters)
# run 10 times
for (iter in 1:iters)
{
# TRAIN
# extract train data by randomly assigning 80% of the data to train
train_index <- createDataPartition(y = input_y, p=.8, list=FALSE)
# extract *training* feature vectors and labels
train_x <- input_x[train_index, ]
train_y <- input_y[train_index]
# get positive index
positive_index <- train_y > 0
# get positive & negative feature data
train_x_positive <- train_x[positive_index, ]
train_x_negative <- train_x[!positive_index,]
# use a normal distribution to model each of the class-conditional distributions
# calculate mean
train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
# calculate standard deviation
train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
# calculate log probability
train_x_positive_offset <- t(t(train_x_positive) - train_x_positive_mean)
train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
train_x_positive_log_prob <- -(1/2)*rowSums(apply(train_x_positive_scaled, c(1, 2), function(x)x^2), na.rm=TRUE) - sum(log(train_x_positive_sd))
train_x_negative_offset <- t(t(train_x_negative) - train_x_negative_mean)
train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
train_x_negative_log_prob <- -(1/2)*rowSums(apply(train_x_negative_scaled, c(1, 2), function(x)x^2), na.rm=TRUE) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
guesses_train <- train_x_positive_log_prob > train_x_negative_log_prob
num_correct_train <- guesses_train == train_y
train_accuracy[iter]<-sum(num_correct_train)/(sum(num_correct_train)+sum(!num_correct_train))
print(train_accuracy[iter])
# ## evaluating - testing data
#
# # extract *testing* feature vectors and labels
# x_vec_test<-x_vec[-wtd, ]
# y_vec_test<-y_vec[-wtd]
#
# # Solve for log probability that each feature vector corresponds to a positive label
# pos_test_offset<-t(t(x_vec_test)-pos_mean)
# pos_test_scaled<-t(t(pos_test_offset)/pos_sd)
# pos_test_log_prob<--(1/2)*rowSums(apply(pos_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(pos_sd))
#
# # Solve for log probability that each feature vector corresponds to a negative label
# neg_test_offset<-t(t(x_vec_test)-neg_mean)
# neg_test_scaled<-t(t(neg_test_offset)/neg_sd)
# neg_test_log_prob<--(1/2)*rowSums(apply(neg_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(neg_sd))
#
# # record percentage guessed correctly in scores array
# guesses_test<-pos_test_log_prob>neg_test_log_prob
# num_correct_test<-guesses_test==y_vec_test
# test_score[iter]<-sum(num_correct_test)/(sum(num_correct_test)+sum(!num_correct_test))
}
# print(test_score)
View(input_x)
# Build a simple naive Bayes classifier to classify this data set.
# load library
library(klaR)
library(caret)
# set current work path
setwd('.')
# read in csv file
input_data<-read.csv('pima-indians-diabetes.txt', header=FALSE)
# split the inputdata
input_x <- input_data[,-c(9)]  # features
input_y <- input_data[,9]      # labels
# number of times
iters = 10
# initialize accuracy
train_accuracy <- array(dim=iters)
test_accuracy <- array(dim=iters)
# run 10 times
for (iter in 1:iters)
{
# TRAIN
# extract train data by randomly assigning 80% of the data to train
train_index <- createDataPartition(y = input_y, p=.8, list=FALSE)
# extract *training* feature vectors and labels
train_x <- input_x[train_index, ]
train_y <- input_y[train_index]
# get positive index
positive_index <- train_y > 0
# get positive & negative feature data
train_x_positive <- train_x[positive_index, ]
train_x_negative <- train_x[!positive_index,]
# use a normal distribution to model each of the class-conditional distributions
# calculate mean
train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
# calculate standard deviation
train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
# calculate log probability
train_x_positive_offset <- t(t(train_x_positive) - train_x_positive_mean)
train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
train_x_positive_log_prob <- -(1/2)*rowSums(apply(train_x_positive_scaled, c(1, 2), function(x)x^2), na.rm=TRUE) - sum(log(train_x_positive_sd))
train_x_negative_offset <- t(t(train_x_negative) - train_x_negative_mean)
train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
train_x_negative_log_prob <- -(1/2)*rowSums(apply(train_x_negative_scaled, c(1, 2), function(x)x^2), na.rm=TRUE) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
guesses_train <- train_x_positive_log_prob > train_x_negative_log_prob
num_correct_train <- guesses_train == train_y
train_accuracy[iter]<-sum(num_correct_train)/(sum(num_correct_train)+sum(!num_correct_train))
print(train_accuracy[iter])
# ## evaluating - testing data
#
# # extract *testing* feature vectors and labels
# x_vec_test<-x_vec[-wtd, ]
# y_vec_test<-y_vec[-wtd]
#
# # Solve for log probability that each feature vector corresponds to a positive label
# pos_test_offset<-t(t(x_vec_test)-pos_mean)
# pos_test_scaled<-t(t(pos_test_offset)/pos_sd)
# pos_test_log_prob<--(1/2)*rowSums(apply(pos_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(pos_sd))
#
# # Solve for log probability that each feature vector corresponds to a negative label
# neg_test_offset<-t(t(x_vec_test)-neg_mean)
# neg_test_scaled<-t(t(neg_test_offset)/neg_sd)
# neg_test_log_prob<--(1/2)*rowSums(apply(neg_test_scaled, c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(neg_sd))
#
# # record percentage guessed correctly in scores array
# guesses_test<-pos_test_log_prob>neg_test_log_prob
# num_correct_test<-guesses_test==y_vec_test
# test_score[iter]<-sum(num_correct_test)/(sum(num_correct_test)+sum(!num_correct_test))
}
# print(test_score)
