#    test_x <- input_x[-train_index, ]
#    test_y <- input_y[-train_index]
#
#    # calculate log probability
#    test_x_positive_offset <- t(t(test_x) - train_x_positive_mean)
#    test_x_positive_scaled <- t(t(test_x_positive_offset) / train_x_positive_sd)
#    test_x_positive_log_prob <- -(1/2)*apply(test_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
#
#    test_x_negative_offset <- t(t(test_x) - train_x_negative_mean)
#    test_x_negative_scaled <- t(t(test_x_negative_offset) / train_x_negative_sd)
#    test_x_negative_log_prob <- -(1/2)*apply(test_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
#
#    # record percentage guessed correctly in scores array
#    test_predict_y <- test_x_positive_log_prob > test_x_negative_log_prob
#    test_correct_account <- test_predict_y == train_y
#    test_accuracy[iter] <- sum(test_correct_account)/(sum(test_correct_account)+sum(!test_correct_account))
#  }
#
# print(test_accuracy)
#
setwd('.')
wdat<-read.csv('pima-indians-diabetes.csv', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)]
bigy<-wdat[,9]
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{wtd<-createDataPartition(y=bigy, p=.8, list=FALSE)
nbx<-bigx
ntrbx<-nbx[wtd, ]
ntrby<-bigy[wtd]
trposflag<-ntrby>0
ptregs<-ntrbx[trposflag, ]
ntregs<-ntrbx[!trposflag,]
ntebx<-nbx[-wtd, ]
nteby<-bigy[-wtd]
ptrmean<-sapply(ptregs, mean, na.rm=TRUE)
ntrmean<-sapply(ntregs, mean, na.rm=TRUE)
ptrsd<-sapply(ptregs, sd, na.rm=TRUE)
ntrsd<-sapply(ntregs, sd, na.rm=TRUE)
ptroffsets<-t(t(ntrbx)-ptrmean)
ptrscales<-t(t(ptroffsets)/ptrsd)
ptrlogs<--(1/2)*rowSums(apply(ptrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
ntroffsets<-t(t(ntrbx)-ntrmean)
ntrscales<-t(t(ntroffsets)/ntrsd)
ntrlogs<--(1/2)*rowSums(apply(ntrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwtr<-ptrlogs>ntrlogs
gotrighttr<-lvwtr==ntrby
trscore[wi]<-sum(gotrighttr)/(sum(gotrighttr)+sum(!gotrighttr))
pteoffsets<-t(t(ntebx)-ptrmean)
ptescales<-t(t(pteoffsets)/ptrsd)
ptelogs<--(1/2)*rowSums(apply(ptescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
nteoffsets<-t(t(ntebx)-ntrmean)
ntescales<-t(t(nteoffsets)/ntrsd)
ntelogs<--(1/2)*rowSums(apply(ntescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwte<-ptelogs>ntelogs
gotright<-lvwte==nteby
tescore[wi]<-sum(gotright)/(sum(gotright)+sum(!gotright))
}
# # Build a simple naive Bayes classifier to classify this data set.
#
# # load library
# library(klaR)
# library(caret)
#
# # set current work path
# setwd('.')
#
# # read in csv file
# input_data <- read.csv('pima-indians-diabetes.csv', header=FALSE)
#
# # split the inputdata
# input_x <- input_data[,-c(9)]  # features
# input_y <- input_data[,9]      # labels
#
# # number of times
# iters = 10
#
# # initialize accuracy
# train_accuracy <- array(dim=iters)
# test_accuracy <- array(dim=iters)
#
# # run 10 times
# for (iter in 1:iters)
# {
#   # TRAIN
#   # extract train data by randomly assigning 80% of the data to train
#   train_index <- createDataPartition(y=input_y, p=.8, list=FALSE)
#
#   # extract training feature vectors and labels
#   train_x <- input_x[train_index, ]
#   train_y <- input_y[train_index]
#
#   # get positive index
#   positive_index <- train_y == 1
#
#   # get positive & negative feature data
#   train_x_positive <- train_x[positive_index, ]
#   train_x_negative <- train_x[!positive_index,]
#
#   # use a normal distribution to model distributions
#   # calculate mean and standard deviation
#   train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
#   train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
#
#   train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
#   train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
#
#   # calculate log probability
#   train_x_positive_offset <- t(t(train_x) - train_x_positive_mean)
#   train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
#   train_x_positive_log_prob <- -(1/2)*apply(train_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
#
#   train_x_negative_offset <- t(t(train_x) - train_x_negative_mean)
#   train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
#   train_x_negative_log_prob <- -(1/2)*apply(train_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
#
#    # record percentage guessed correctly in scores array
#    train_predict_y <- train_x_positive_log_prob > train_x_negative_log_prob
#    train_correct_account <- train_predict_y == train_y
#    train_accuracy[iter] <- sum(train_correct_account)/(sum(train_correct_account)+sum(!train_correct_account))
#
#    # TEST
#    # extract feature vectors and labels
#    test_x <- input_x[-train_index, ]
#    test_y <- input_y[-train_index]
#
#    # calculate log probability
#    test_x_positive_offset <- t(t(test_x) - train_x_positive_mean)
#    test_x_positive_scaled <- t(t(test_x_positive_offset) / train_x_positive_sd)
#    test_x_positive_log_prob <- -(1/2)*apply(test_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
#
#    test_x_negative_offset <- t(t(test_x) - train_x_negative_mean)
#    test_x_negative_scaled <- t(t(test_x_negative_offset) / train_x_negative_sd)
#    test_x_negative_log_prob <- -(1/2)*apply(test_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
#
#    # record percentage guessed correctly in scores array
#    test_predict_y <- test_x_positive_log_prob > test_x_negative_log_prob
#    test_correct_account <- test_predict_y == train_y
#    test_accuracy[iter] <- sum(test_correct_account)/(sum(test_correct_account)+sum(!test_correct_account))
#  }
#
# print(test_accuracy)
#
setwd('.')
wdat<-read.csv('pima-indians-diabetes.csv', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)]
bigy<-wdat[,9]
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{wtd<-createDataPartition(y=bigy, p=.8, list=FALSE)
nbx<-bigx
ntrbx<-nbx[wtd, ]
ntrby<-bigy[wtd]
trposflag<-ntrby>0
ptregs<-ntrbx[trposflag, ]
ntregs<-ntrbx[!trposflag,]
ntebx<-nbx[-wtd, ]
nteby<-bigy[-wtd]
ptrmean<-sapply(ptregs, mean, na.rm=TRUE)
ntrmean<-sapply(ntregs, mean, na.rm=TRUE)
ptrsd<-sapply(ptregs, sd, na.rm=TRUE)
ntrsd<-sapply(ntregs, sd, na.rm=TRUE)
ptroffsets<-t(t(ntrbx)-ptrmean)
ptrscales<-t(t(ptroffsets)/ptrsd)
ptrlogs<--(1/2)*rowSums(apply(ptrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
ntroffsets<-t(t(ntrbx)-ntrmean)
ntrscales<-t(t(ntroffsets)/ntrsd)
ntrlogs<--(1/2)*rowSums(apply(ntrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwtr<-ptrlogs>ntrlogs
gotrighttr<-lvwtr==ntrby
trscore[wi]<-sum(gotrighttr)/(sum(gotrighttr)+sum(!gotrighttr))
pteoffsets<-t(t(ntebx)-ptrmean)
ptescales<-t(t(pteoffsets)/ptrsd)
ptelogs<--(1/2)*rowSums(apply(ptescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
nteoffsets<-t(t(ntebx)-ntrmean)
ntescales<-t(t(nteoffsets)/ntrsd)
ntelogs<--(1/2)*rowSums(apply(ntescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwte<-ptelogs>ntelogs
gotright<-lvwte==nteby
tescore[wi]<-sum(gotright)/(sum(gotright)+sum(!gotright))
}
print(tescore)
# Build a simple naive Bayes classifier to classify this data set.
# load library
library(klaR)
library(caret)
# set current work path
setwd('.')
# read in csv file
input_data <- read.csv('pima-indians-diabetes.csv', header=FALSE)
# split the inputdata
input_x <- input_data[,-c(9)]  # features
input_y <- input_data[,9]      # labels
# number of times
iters = 10
# initialize accuracy
train_accuracy <- array(dim=iters)
test_accuracy <- array(dim=iters)
# run 10 times
for (iter in 1:iters)
{
# TRAIN
# extract train data by randomly assigning 80% of the data to train
train_index <- createDataPartition(y=input_y, p=.8, list=FALSE)
# extract training feature vectors and labels
train_x <- input_x[train_index, ]
train_y <- input_y[train_index]
# get positive index
positive_index <- train_y == 1
# get positive & negative feature data
train_x_positive <- train_x[positive_index, ]
train_x_negative <- train_x[!positive_index,]
# use a normal distribution to model distributions
# calculate mean and standard deviation
train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
# calculate log probability
train_x_positive_offset <- t(t(train_x) - train_x_positive_mean)
train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
train_x_positive_log_prob <- -(1/2)*apply(train_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
train_x_negative_offset <- t(t(train_x) - train_x_negative_mean)
train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
train_x_negative_log_prob <- -(1/2)*apply(train_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
train_predict_y <- train_x_positive_log_prob > train_x_negative_log_prob
train_correct_account <- train_predict_y == train_y
train_accuracy[iter] <- sum(train_correct_account)/(sum(train_correct_account)+sum(!train_correct_account))
# TEST
# extract feature vectors and labels
test_x <- input_x[-train_index, ]
test_y <- input_y[-train_index]
# calculate log probability
test_x_positive_offset <- t(t(test_x) - train_x_positive_mean)
test_x_positive_scaled <- t(t(test_x_positive_offset) / train_x_positive_sd)
test_x_positive_log_prob <- -(1/2)*apply(test_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
test_x_negative_offset <- t(t(test_x) - train_x_negative_mean)
test_x_negative_scaled <- t(t(test_x_negative_offset) / train_x_negative_sd)
test_x_negative_log_prob <- -(1/2)*apply(test_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
test_predict_y <- test_x_positive_log_prob > test_x_negative_log_prob
test_correct_account <- test_predict_y == test_y
test_accuracy[iter] <- sum(test_correct_account)/(sum(test_correct_account)+sum(!test_correct_account))
}
print(test_accuracy)
# Build a simple naive Bayes classifier to classify this data set.
# load library
library(klaR)
library(caret)
# set current work path
setwd('.')
# read in csv file
input_data <- read.csv('pima-indians-diabetes.csv', header=FALSE)
# split the inputdata
input_x <- input_data[,-c(9)]  # features
input_y <- input_data[,9]      # labels
# number of times
iters = 10
# initialize accuracy
train_accuracy <- array(dim=iters)
test_accuracy <- array(dim=iters)
# run 10 times
for (iter in 1:iters)
{
# TRAIN
# extract train data by randomly assigning 80% of the data to train
train_index <- createDataPartition(y=input_y, p=.8, list=FALSE)
# extract training feature vectors and labels
train_x <- input_x[train_index, ]
train_y <- input_y[train_index]
# get positive index
positive_index <- train_y == 1
# get positive & negative feature data
train_x_positive <- train_x[positive_index, ]
train_x_negative <- train_x[!positive_index,]
# use a normal distribution to model distributions
# calculate mean and standard deviation
train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
# calculate log probability
train_x_positive_offset <- t(t(train_x) - train_x_positive_mean)
train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
train_x_positive_log_prob <- -(1/2)*apply(train_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
train_x_negative_offset <- t(t(train_x) - train_x_negative_mean)
train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
train_x_negative_log_prob <- -(1/2)*apply(train_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
train_predict_y <- train_x_positive_log_prob > train_x_negative_log_prob
train_correct_account <- train_predict_y == train_y
train_accuracy[iter] <- sum(train_correct_account)/(sum(train_correct_account)+sum(!train_correct_account))
# TEST
# extract feature vectors and labels
test_x <- input_x[-train_index, ]
test_y <- input_y[-train_index]
# calculate log probability
test_x_positive_offset <- t(t(test_x) - train_x_positive_mean)
test_x_positive_scaled <- t(t(test_x_positive_offset) / train_x_positive_sd)
test_x_positive_log_prob <- -(1/2)*apply(test_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
test_x_negative_offset <- t(t(test_x) - train_x_negative_mean)
test_x_negative_scaled <- t(t(test_x_negative_offset) / train_x_negative_sd)
test_x_negative_log_prob <- -(1/2)*apply(test_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
test_predict_y <- test_x_positive_log_prob > test_x_negative_log_prob
test_correct_account <- test_predict_y == test_y
test_accuracy[iter] <- sum(test_correct_account)/(sum(test_correct_account)+sum(!test_correct_account))
}
result <- sapply(test_accuracy, mean, na.rm=TRUE)
print(result)
# Build a simple naive Bayes classifier to classify this data set.
# load library
library(klaR)
library(caret)
# set current work path
setwd('.')
# read in csv file
input_data <- read.csv('pima-indians-diabetes.csv', header=FALSE)
# split the inputdata
input_x <- input_data[,-c(9)]  # features
input_y <- input_data[,9]      # labels
# number of times
iters = 10
# initialize accuracy
train_accuracy <- array(dim=iters)
test_accuracy <- array(dim=iters)
# run 10 times
for (iter in 1:iters)
{
# TRAIN
# extract train data by randomly assigning 80% of the data to train
train_index <- createDataPartition(y=input_y, p=.8, list=FALSE)
# extract training feature vectors and labels
train_x <- input_x[train_index, ]
train_y <- input_y[train_index]
# get positive index
positive_index <- train_y == 1
# get positive & negative feature data
train_x_positive <- train_x[positive_index, ]
train_x_negative <- train_x[!positive_index,]
# use a normal distribution to model distributions
# calculate mean and standard deviation
train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
# calculate log probability
train_x_positive_offset <- t(t(train_x) - train_x_positive_mean)
train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
train_x_positive_log_prob <- -(1/2)*apply(train_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
train_x_negative_offset <- t(t(train_x) - train_x_negative_mean)
train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
train_x_negative_log_prob <- -(1/2)*apply(train_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
train_predict_y <- train_x_positive_log_prob > train_x_negative_log_prob
train_correct_account <- train_predict_y == train_y
train_accuracy[iter] <- sum(train_correct_account)/(sum(train_correct_account)+sum(!train_correct_account))
# TEST
# extract feature vectors and labels
test_x <- input_x[-train_index, ]
test_y <- input_y[-train_index]
# calculate log probability
test_x_positive_offset <- t(t(test_x) - train_x_positive_mean)
test_x_positive_scaled <- t(t(test_x_positive_offset) / train_x_positive_sd)
test_x_positive_log_prob <- -(1/2)*apply(test_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
test_x_negative_offset <- t(t(test_x) - train_x_negative_mean)
test_x_negative_scaled <- t(t(test_x_negative_offset) / train_x_negative_sd)
test_x_negative_log_prob <- -(1/2)*apply(test_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
test_predict_y <- test_x_positive_log_prob > test_x_negative_log_prob
test_correct_account <- test_predict_y == test_y
test_accuracy[iter] <- sum(test_correct_account)/(sum(test_correct_account)+sum(!test_correct_account))
}
result <- mean(test_accuracy)
print(result)
# Build a simple naive Bayes classifier to classify this data set.
# load library
library(klaR)
library(caret)
# set current work path
setwd('.')
# read in csv file
input_data <- read.csv('pima-indians-diabetes.csv', header=FALSE)
# split the inputdata
input_x <- input_data[,-c(9)]  # features
input_y <- input_data[,9]      # labels
# number of times
iters = 10
# initialize accuracy
train_accuracy <- array(dim=iters)
test_accuracy <- array(dim=iters)
# run 10 times
for (iter in 1:iters)
{
# TRAIN
# extract train data by randomly assigning 80% of the data to train
train_index <- createDataPartition(y=input_y, p=.8, list=FALSE)
# extract training feature vectors and labels
train_x <- input_x[train_index, ]
train_y <- input_y[train_index]
# get positive index
positive_index <- train_y == 1
# get positive & negative feature data
train_x_positive <- train_x[positive_index, ]
train_x_negative <- train_x[!positive_index,]
# use a normal distribution to model distributions
# calculate mean and standard deviation
train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
# calculate log probability
train_x_positive_offset <- t(t(train_x) - train_x_positive_mean)
train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
train_x_positive_log_prob <- -(1/2)*apply(train_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
train_x_negative_offset <- t(t(train_x) - train_x_negative_mean)
train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
train_x_negative_log_prob <- -(1/2)*apply(train_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
train_predict_y <- train_x_positive_log_prob > train_x_negative_log_prob
train_correct_account <- train_predict_y == train_y
train_accuracy[iter] <- sum(train_correct_account)/(sum(train_correct_account)+sum(!train_correct_account))
# TEST
# extract feature vectors and labels
test_x <- input_x[-train_index, ]
test_y <- input_y[-train_index]
# calculate log probability
test_x_positive_offset <- t(t(test_x) - train_x_positive_mean)
test_x_positive_scaled <- t(t(test_x_positive_offset) / train_x_positive_sd)
test_x_positive_log_prob <- -(1/2)*apply(test_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
test_x_negative_offset <- t(t(test_x) - train_x_negative_mean)
test_x_negative_scaled <- t(t(test_x_negative_offset) / train_x_negative_sd)
test_x_negative_log_prob <- -(1/2)*apply(test_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
test_predict_y <- test_x_positive_log_prob > test_x_negative_log_prob
test_correct_account <- test_predict_y == test_y
test_accuracy[iter] <- sum(test_correct_account)/(sum(test_correct_account)+sum(!test_correct_account))
}
result <- mean(test_accuracy)
print(result)
# Build a simple naive Bayes classifier to classify this data set.
# load library
library(klaR)
library(caret)
# set current work path
setwd('.')
# read in csv file
input_data <- read.csv('pima-indians-diabetes.csv', header=FALSE)
# split the inputdata
input_x <- input_data[,-c(9)]  # features
input_y <- input_data[,9]      # labels
# number of times
iters = 10
# initialize accuracy
train_accuracy <- array(dim=iters)
test_accuracy <- array(dim=iters)
# run 10 times
for (iter in 1:iters)
{
# TRAIN
# extract train data by randomly assigning 80% of the data to train
train_index <- createDataPartition(y=input_y, p=.8, list=FALSE)
# extract training feature vectors and labels
train_x <- input_x[train_index, ]
train_y <- input_y[train_index]
# get positive index
positive_index <- train_y == 1
# get positive & negative feature data
train_x_positive <- train_x[positive_index, ]
train_x_negative <- train_x[!positive_index,]
# use a normal distribution to model distributions
# calculate mean and standard deviation
train_x_positive_mean <- sapply(train_x_positive, mean, na.rm=TRUE)
train_x_negative_mean <- sapply(train_x_negative, mean, na.rm=TRUE)
train_x_positive_sd <- sapply(train_x_positive, sd, na.rm=TRUE)
train_x_negative_sd <- sapply(train_x_negative, sd, na.rm=TRUE)
# calculate log probability
train_x_positive_offset <- t(t(train_x) - train_x_positive_mean)
train_x_positive_scaled <- t(t(train_x_positive_offset) / train_x_positive_sd)
train_x_positive_log_prob <- -(1/2)*apply(train_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
train_x_negative_offset <- t(t(train_x) - train_x_negative_mean)
train_x_negative_scaled <- t(t(train_x_negative_offset) / train_x_negative_sd)
train_x_negative_log_prob <- -(1/2)*apply(train_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
train_predict_y <- train_x_positive_log_prob > train_x_negative_log_prob
train_correct_account <- train_predict_y == train_y
train_accuracy[iter] <- sum(train_correct_account)/(sum(train_correct_account)+sum(!train_correct_account))
# TEST
# extract feature vectors and labels
test_x <- input_x[-train_index, ]
test_y <- input_y[-train_index]
# calculate log probability
test_x_positive_offset <- t(t(test_x) - train_x_positive_mean)
test_x_positive_scaled <- t(t(test_x_positive_offset) / train_x_positive_sd)
test_x_positive_log_prob <- -(1/2)*apply(test_x_positive_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_positive_sd))
test_x_negative_offset <- t(t(test_x) - train_x_negative_mean)
test_x_negative_scaled <- t(t(test_x_negative_offset) / train_x_negative_sd)
test_x_negative_log_prob <- -(1/2)*apply(test_x_negative_scaled, 1, function(x){sum(x^2)}) - sum(log(train_x_negative_sd))
# record percentage guessed correctly in scores array
test_predict_y <- test_x_positive_log_prob > test_x_negative_log_prob
test_correct_account <- test_predict_y == test_y
test_accuracy[iter] <- sum(test_correct_account)/(sum(test_correct_account)+sum(!test_correct_account))
}
result <- mean(test_accuracy)
print(result)
